# ğŸ§  Fake News Detection using Machine Learning & Sentiment Intelligence

<div align="center">

ğŸš€ Comparative ML Study | ğŸ“Š Result-Based Evaluation | ğŸŒ Web Scraping | ğŸ’¬ Sentiment Analysis  

</div>

---

## ğŸŒ Project Vision

In the age of digital misinformation, detecting fake news is no longer optional â€” it is essential.

This project presents a **comprehensive, result-driven comparative analysis** of six Machine Learning models for Fake News Detection, enhanced with real-time web scraping and sentiment intelligence.

It is designed not just as a classification system, but as a **research-ready analytical framework** for evaluating model performance, computational trade-offs, and emotional polarity patterns in misinformation.

---

# ğŸ— System Architecture

```
Raw Dataset + Scraped News
            â”‚
            â–¼
   Data Preprocessing
            â”‚
            â–¼
      TF-IDF Vectorization
            â”‚
            â–¼
  Model Segmentation Strategy
   â”œâ”€â”€ Lightweight Models
   â””â”€â”€ Heavyweight Models
            â”‚
            â–¼
   Evaluation & Visualization
            â”‚
            â–¼
   Sentiment Intelligence Layer
            â”‚
            â–¼
      Exportable Results
```

---

# ğŸ§ª Models Implemented

## ğŸ”¹ Lightweight Models (Full Dataset)

Optimized for speed and scalability.

- âœ… Multinomial Naive Bayes  
- âœ… Logistic Regression (GridSearchCV tuned)  
- âœ… K-Nearest Neighbors  

These models are trained on the full dataset to observe generalization performance.

---

## ğŸ”¹ Heavyweight Models (Sampled Dataset)

Optimized for deeper decision boundaries and ensemble intelligence.

- âœ… Support Vector Machine (Linear Kernel, optimized runtime)  
- âœ… Random Forest (Controlled depth & estimators)  
- âœ… XGBoost (Parallel optimized)  

Heavy models are trained on a reduced dataset fraction to maintain computational efficiency while preserving analytical depth.

---

# ğŸ“Š Evaluation Framework

Each model is evaluated using:

- ğŸ”¹ Accuracy  
- ğŸ”¹ Precision  
- ğŸ”¹ Recall  
- ğŸ”¹ F1-Score  
- ğŸ”¹ Confusion Matrix  
- ğŸ”¹ ROC Curve (AUC)  
- ğŸ”¹ Precision-Recall Curve  

Additionally, a **Sentiment Intelligence Layer** provides:

- Average VADER Compound Sentiment Score  
- Average sentiment for predictions labeled Fake  
- Average sentiment for predictions labeled Real  

Results are exported as:

```
light_model_results.csv
heavy_model_results.csv
```

This enables direct inclusion into research papers or comparative studies.

---

# ğŸ’¬ Sentiment Intelligence Layer

We integrate **VADER (Valence Aware Dictionary for Sentiment Reasoning)** to analyze the emotional polarity of news content.

Each news article receives:

- Compound sentiment score
- Polarity classification:
  - Positive
  - Neutral
  - Negative

This allows us to analyze:

> Do fake news articles exhibit stronger emotional polarity than real news?

This hybrid architecture makes the system not just predictive â€” but analytical.

---

# ğŸŒ Real-Time Web Scraping Integration

To enrich the dataset and maintain realism:

The system scrapes headlines from:

- BBC News  
- CNN World  
- Reuters  

Scraped articles are automatically labeled as Real (0) and appended before training.

This ensures dynamic dataset augmentation.

---

# ğŸ“‚ Dataset Description

Main dataset file:

```
updated_news_dataset.csv
```

Columns:

| Column | Description |
|--------|-------------|
| text   | News content |
| label  | 1 = Fake, 0 = Real |

The dataset includes:

- Fake news articles  
- Verified real news articles  
- Live scraped headlines  

---

# âš™ï¸ Technical Stack

- Python  
- Scikit-learn  
- XGBoost  
- NLTK (VADER Sentiment Analyzer)  
- Pandas  
- Matplotlib  
- Seaborn  
- BeautifulSoup (Web Scraping)  
- Google Colab  
- Joblib (Model & Vectorizer Persistence)

---

# ğŸš€ How to Run

## 1ï¸âƒ£ Mount Drive (Google Colab)

```python
from google.colab import drive
drive.mount('/content/drive')
```

## 2ï¸âƒ£ Install Dependencies (if needed)

```bash
pip install xgboost nltk seaborn beautifulsoup4
```

## 3ï¸âƒ£ Run Lightweight Notebook

- Uses full dataset  
- Trains NB, LR, KNN  
- Generates evaluation plots  
- Saves `light_model_results.csv`

## 4ï¸âƒ£ Run Heavyweight Notebook

- Uses sampled dataset  
- Trains SVM, Random Forest, XGBoost  
- Generates evaluation plots  
- Saves `heavy_model_results.csv`

---

# ğŸ§  Key Engineering Decisions

âœ” Segmented model architecture (Light vs Heavy)  
âœ” Runtime optimization using dataset sampling  
âœ” TF-IDF caching for faster re-runs  
âœ” Decision function for SVM to reduce training time  
âœ” Parallel training for ensemble models  
âœ” Structured evaluation for research reproducibility  

---

# ğŸ“ˆ Research & Analytical Value

This project enables:

- Empirical comparison across 6 ML algorithms  
- Computational complexity vs performance analysis  
- Emotional polarity study in misinformation  
- ROC vs PR curve tradeoff evaluation  
- Exportable research-grade results  

It is suitable for:

- Academic Review Papers  
- Machine Learning Portfolios  
- Applied NLP Research  
- Interview Demonstrations  

---

# ğŸ“ Project Structure

```
FakeNewsProject/
â”‚
â”œâ”€â”€ updated_news_dataset.csv
â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚
â”œâ”€â”€ lightweight_models.ipynb
â”œâ”€â”€ heavyweight_models.ipynb
â”‚
â”œâ”€â”€ light_model_results.csv
â”œâ”€â”€ heavy_model_results.csv
â”‚
â””â”€â”€ README.md
```

---

# ğŸ”® Future Enhancements

- Deep Learning models (LSTM / BERT)
- Transformer-based fake news classification
- Real-time API deployment
- Web dashboard visualization
- Explainable AI integration (SHAP / LIME)
- Automated hyperparameter optimization

---

# ğŸ‘¨â€ğŸ’» Author

Machine Learning Project  
Fake News Detection using Sentiment Analysis  
Comparative ML Evaluation Framework  

---

<div align="center">

â­ If you found this project insightful, consider starring the repository!

</div>
